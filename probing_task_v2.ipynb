{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset trec (C:\\Users\\Prophet.DESKTOP-UUFA83J\\.cache\\huggingface\\datasets\\trec\\default\\1.1.0\\751da1ab101b8d297a3d6e9c79ee9b0173ff94c4497b75677b59b61d5467a9b9)\n",
      "Using custom data configuration default\n",
      "Reusing dataset trec (C:\\Users\\Prophet.DESKTOP-UUFA83J\\.cache\\huggingface\\datasets\\trec\\default\\1.1.0\\751da1ab101b8d297a3d6e9c79ee9b0173ff94c4497b75677b59b61d5467a9b9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 'What country do the Galapagos Islands belong to ?')\n",
      "('What country do the Galapagos Islands belong to ?', 18)\n",
      "['What are amphibians ?', 7]\n",
      "5452\n",
      "load model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f2ca3c8f1a4d0f8f3391d53082928a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=265481570.0, style=ProgressStyle(descriâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering as Model\n",
    "from transformers import DistilBertTokenizer as Tokenizer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset_hg = load_dataset('trec', split='train')\n",
    "test_dataset_hg  = load_dataset('trec', split='test')\n",
    "print((train_dataset_hg[50]['label-fine'], train_dataset_hg[50]['text']))\n",
    "#prepare_dataset\n",
    "train_dataset = []\n",
    "for data in train_dataset_hg:\n",
    "    train_dataset.append((data['text'], data['label-fine']))\n",
    "test_dataset = []\n",
    "for data in test_dataset_hg:\n",
    "    test_dataset.append([data['text'], data['label-fine']])\n",
    "\n",
    "print(train_dataset[50])\n",
    "print(test_dataset [50])\n",
    "print(len(train_dataset))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"load model\")\n",
    "    model_name = 'distilbert-base-uncased-distilled-squad'\n",
    "    tokenizer = Tokenizer.from_pretrained(model_name)\n",
    "    model = Model.from_pretrained(model_name, return_dict=True)\n",
    "    print(\"model loaded\")\n",
    "\n",
    "\n",
    "    squad_question = \"What is a common punishment in the UK and Ireland?\"\n",
    "\n",
    "    squad_context = \"Currently detention is one of the most common punishments in schools in the United States, the UK, Ireland, \" \\\n",
    "              \"Singapore and other countries. It requires the pupil to remain in school at a given time in the school day \" \\\n",
    "              \"(such as lunch, recess or after school); or even to attend school on a non-school day, e.g. Saturday detention \" \\\n",
    "              \"held at some schools. During detention,students normally have to sit in a classroom and do work, write lines or\" \\\n",
    "              \" a punishment essay, or sit quietly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionSentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AttentionSentimentClassifier, self).__init__()\n",
    "        #Fully connected to probe the model using the fine-grained answer type of the trec dataset\n",
    "        self.fc = nn.Linear(400, 47)\n",
    "        self.classify = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.classify(self.fc(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def QA_type_probing(question, context, model, tokenizer):\n",
    "    question_ids = tokenizer.encode(question)\n",
    "    context_ids  = tokenizer.encode(context)\n",
    "    input_ids = question_ids + context_ids\n",
    "    output = model(torch.tensor([input_ids]), output_hidden_states=True, return_dict=True)\n",
    "    #start_scores = output.start_logits\n",
    "    #end_scores = output.end_logits\n",
    "    #answer_start = torch.argmax(start_scores)\n",
    "    #answer_end = torch.argmax(end_scores)\n",
    "    #tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    #answer = ' '.join(tokens[answer_start:answer_end + 1]).replace(\" ##\", \"\")\n",
    "    #print(answer)\n",
    "    print(output.hidden_states.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
